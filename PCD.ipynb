{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01f36495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14176608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>0.765359</td>\n",
       "      <td>6.131991</td>\n",
       "      <td>8.556782</td>\n",
       "      <td>5.797011</td>\n",
       "      <td>3.347837</td>\n",
       "      <td>-0.965365</td>\n",
       "      <td>-1.166428</td>\n",
       "      <td>-1.216044</td>\n",
       "      <td>0.938925</td>\n",
       "      <td>0.822822</td>\n",
       "      <td>0.637312</td>\n",
       "      <td>0.492588</td>\n",
       "      <td>0.023237</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4646</th>\n",
       "      <td>9.067146</td>\n",
       "      <td>9.472926</td>\n",
       "      <td>8.140089</td>\n",
       "      <td>6.143941</td>\n",
       "      <td>3.307202</td>\n",
       "      <td>-1.455176</td>\n",
       "      <td>-0.526021</td>\n",
       "      <td>-1.326005</td>\n",
       "      <td>0.265468</td>\n",
       "      <td>0.707036</td>\n",
       "      <td>0.081933</td>\n",
       "      <td>0.707150</td>\n",
       "      <td>0.042692</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9299</th>\n",
       "      <td>3.653564</td>\n",
       "      <td>4.333105</td>\n",
       "      <td>4.656519</td>\n",
       "      <td>0.877623</td>\n",
       "      <td>4.871209</td>\n",
       "      <td>-1.842062</td>\n",
       "      <td>-1.746068</td>\n",
       "      <td>-1.283080</td>\n",
       "      <td>0.703868</td>\n",
       "      <td>0.180876</td>\n",
       "      <td>0.079064</td>\n",
       "      <td>0.306750</td>\n",
       "      <td>-0.027009</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6906</th>\n",
       "      <td>8.757373</td>\n",
       "      <td>8.137797</td>\n",
       "      <td>3.184345</td>\n",
       "      <td>8.983953</td>\n",
       "      <td>4.285288</td>\n",
       "      <td>-1.461420</td>\n",
       "      <td>-0.905590</td>\n",
       "      <td>-1.918278</td>\n",
       "      <td>0.171078</td>\n",
       "      <td>0.911105</td>\n",
       "      <td>0.298608</td>\n",
       "      <td>0.360649</td>\n",
       "      <td>0.035485</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7557</th>\n",
       "      <td>9.442515</td>\n",
       "      <td>0.578507</td>\n",
       "      <td>1.545592</td>\n",
       "      <td>4.114449</td>\n",
       "      <td>4.801929</td>\n",
       "      <td>-1.755810</td>\n",
       "      <td>-1.718710</td>\n",
       "      <td>-1.327410</td>\n",
       "      <td>0.278588</td>\n",
       "      <td>0.785834</td>\n",
       "      <td>0.936022</td>\n",
       "      <td>0.450190</td>\n",
       "      <td>-0.047631</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "1117  0.765359  6.131991  8.556782  5.797011  3.347837 -0.965365 -1.166428   \n",
       "4646  9.067146  9.472926  8.140089  6.143941  3.307202 -1.455176 -0.526021   \n",
       "9299  3.653564  4.333105  4.656519  0.877623  4.871209 -1.842062 -1.746068   \n",
       "6906  8.757373  8.137797  3.184345  8.983953  4.285288 -1.461420 -0.905590   \n",
       "7557  9.442515  0.578507  1.545592  4.114449  4.801929 -1.755810 -1.718710   \n",
       "\n",
       "            p4        g1        g2        g3        g4      stab     stabf  \n",
       "1117 -1.216044  0.938925  0.822822  0.637312  0.492588  0.023237  unstable  \n",
       "4646 -1.326005  0.265468  0.707036  0.081933  0.707150  0.042692  unstable  \n",
       "9299 -1.283080  0.703868  0.180876  0.079064  0.306750 -0.027009    stable  \n",
       "6906 -1.918278  0.171078  0.911105  0.298608  0.360649  0.035485  unstable  \n",
       "7557 -1.327410  0.278588  0.785834  0.936022  0.450190 -0.047631    stable  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"Data_for_UCI_named.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bae7a751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996d287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stabf']=df['stabf'].replace(['unstable','stable'],['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f2d2f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>8.886992</td>\n",
       "      <td>8.012393</td>\n",
       "      <td>2.834047</td>\n",
       "      <td>5.722050</td>\n",
       "      <td>3.852568</td>\n",
       "      <td>-1.174230</td>\n",
       "      <td>-0.948859</td>\n",
       "      <td>-1.729479</td>\n",
       "      <td>0.987438</td>\n",
       "      <td>0.207139</td>\n",
       "      <td>0.421279</td>\n",
       "      <td>0.668781</td>\n",
       "      <td>0.049201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>3.176332</td>\n",
       "      <td>5.101491</td>\n",
       "      <td>8.134258</td>\n",
       "      <td>4.985496</td>\n",
       "      <td>3.031084</td>\n",
       "      <td>-0.957564</td>\n",
       "      <td>-1.102893</td>\n",
       "      <td>-0.970628</td>\n",
       "      <td>0.527206</td>\n",
       "      <td>0.774756</td>\n",
       "      <td>0.180754</td>\n",
       "      <td>0.209837</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>5.806376</td>\n",
       "      <td>2.969342</td>\n",
       "      <td>2.873816</td>\n",
       "      <td>5.080283</td>\n",
       "      <td>4.455209</td>\n",
       "      <td>-1.407880</td>\n",
       "      <td>-1.707970</td>\n",
       "      <td>-1.339358</td>\n",
       "      <td>0.086858</td>\n",
       "      <td>0.237457</td>\n",
       "      <td>0.826670</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>-0.039174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7430</th>\n",
       "      <td>8.480938</td>\n",
       "      <td>8.864988</td>\n",
       "      <td>5.278409</td>\n",
       "      <td>3.223676</td>\n",
       "      <td>3.792231</td>\n",
       "      <td>-1.508372</td>\n",
       "      <td>-0.616035</td>\n",
       "      <td>-1.667824</td>\n",
       "      <td>0.897338</td>\n",
       "      <td>0.341999</td>\n",
       "      <td>0.225583</td>\n",
       "      <td>0.171201</td>\n",
       "      <td>0.031979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>6.116803</td>\n",
       "      <td>3.941364</td>\n",
       "      <td>2.316410</td>\n",
       "      <td>3.092281</td>\n",
       "      <td>3.885878</td>\n",
       "      <td>-1.731135</td>\n",
       "      <td>-1.500781</td>\n",
       "      <td>-0.653962</td>\n",
       "      <td>0.780690</td>\n",
       "      <td>0.755883</td>\n",
       "      <td>0.600049</td>\n",
       "      <td>0.955691</td>\n",
       "      <td>0.072207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "2960  8.886992  8.012393  2.834047  5.722050  3.852568 -1.174230 -0.948859   \n",
       "9987  3.176332  5.101491  8.134258  4.985496  3.031084 -0.957564 -1.102893   \n",
       "3659  5.806376  2.969342  2.873816  5.080283  4.455209 -1.407880 -1.707970   \n",
       "7430  8.480938  8.864988  5.278409  3.223676  3.792231 -1.508372 -0.616035   \n",
       "194   6.116803  3.941364  2.316410  3.092281  3.885878 -1.731135 -1.500781   \n",
       "\n",
       "            p4        g1        g2        g3        g4      stab stabf  \n",
       "2960 -1.729479  0.987438  0.207139  0.421279  0.668781  0.049201     0  \n",
       "9987 -0.970628  0.527206  0.774756  0.180754  0.209837  0.010610     0  \n",
       "3659 -1.339358  0.086858  0.237457  0.826670  0.104431 -0.039174     1  \n",
       "7430 -1.667824  0.897338  0.341999  0.225583  0.171201  0.031979     0  \n",
       "194  -0.653962  0.780690  0.755883  0.600049  0.955691  0.072207     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4356c09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.250001</td>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249997</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.015731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.742548</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742556</td>\n",
       "      <td>0.752160</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.036919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.500793</td>\n",
       "      <td>0.500141</td>\n",
       "      <td>0.500788</td>\n",
       "      <td>0.500473</td>\n",
       "      <td>1.582590</td>\n",
       "      <td>-1.999891</td>\n",
       "      <td>-1.999945</td>\n",
       "      <td>-1.999926</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.050053</td>\n",
       "      <td>0.050054</td>\n",
       "      <td>0.050028</td>\n",
       "      <td>-0.080760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.874892</td>\n",
       "      <td>2.875140</td>\n",
       "      <td>2.875522</td>\n",
       "      <td>2.874950</td>\n",
       "      <td>3.218300</td>\n",
       "      <td>-1.624901</td>\n",
       "      <td>-1.625025</td>\n",
       "      <td>-1.624960</td>\n",
       "      <td>0.287521</td>\n",
       "      <td>0.287552</td>\n",
       "      <td>0.287514</td>\n",
       "      <td>0.287494</td>\n",
       "      <td>-0.015557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249981</td>\n",
       "      <td>5.249979</td>\n",
       "      <td>5.249734</td>\n",
       "      <td>3.751025</td>\n",
       "      <td>-1.249966</td>\n",
       "      <td>-1.249974</td>\n",
       "      <td>-1.250007</td>\n",
       "      <td>0.525009</td>\n",
       "      <td>0.525003</td>\n",
       "      <td>0.525015</td>\n",
       "      <td>0.525002</td>\n",
       "      <td>0.017142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.624690</td>\n",
       "      <td>7.624893</td>\n",
       "      <td>7.624948</td>\n",
       "      <td>7.624838</td>\n",
       "      <td>4.282420</td>\n",
       "      <td>-0.874977</td>\n",
       "      <td>-0.875043</td>\n",
       "      <td>-0.875065</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>0.762490</td>\n",
       "      <td>0.762440</td>\n",
       "      <td>0.762433</td>\n",
       "      <td>0.044878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999469</td>\n",
       "      <td>9.999837</td>\n",
       "      <td>9.999450</td>\n",
       "      <td>9.999443</td>\n",
       "      <td>5.864418</td>\n",
       "      <td>-0.500108</td>\n",
       "      <td>-0.500072</td>\n",
       "      <td>-0.500025</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.109403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tau1          tau2          tau3          tau4            p1  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       5.250000      5.250001      5.250004      5.249997      3.750000   \n",
       "std        2.742548      2.742549      2.742549      2.742556      0.752160   \n",
       "min        0.500793      0.500141      0.500788      0.500473      1.582590   \n",
       "25%        2.874892      2.875140      2.875522      2.874950      3.218300   \n",
       "50%        5.250004      5.249981      5.249979      5.249734      3.751025   \n",
       "75%        7.624690      7.624893      7.624948      7.624838      4.282420   \n",
       "max        9.999469      9.999837      9.999450      9.999443      5.864418   \n",
       "\n",
       "                 p2            p3            p4            g1            g2  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      -1.250000     -1.250000     -1.250000      0.525000      0.525000   \n",
       "std        0.433035      0.433035      0.433035      0.274256      0.274255   \n",
       "min       -1.999891     -1.999945     -1.999926      0.050009      0.050053   \n",
       "25%       -1.624901     -1.625025     -1.624960      0.287521      0.287552   \n",
       "50%       -1.249966     -1.249974     -1.250007      0.525009      0.525003   \n",
       "75%       -0.874977     -0.875043     -0.875065      0.762435      0.762490   \n",
       "max       -0.500108     -0.500072     -0.500025      0.999937      0.999944   \n",
       "\n",
       "                 g3            g4          stab  \n",
       "count  10000.000000  10000.000000  10000.000000  \n",
       "mean       0.525000      0.525000      0.015731  \n",
       "std        0.274255      0.274255      0.036919  \n",
       "min        0.050054      0.050028     -0.080760  \n",
       "25%        0.287514      0.287494     -0.015557  \n",
       "50%        0.525015      0.525002      0.017142  \n",
       "75%        0.762440      0.762433      0.044878  \n",
       "max        0.999982      0.999930      0.109403  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8456060d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     float64\n",
       "tau2     float64\n",
       "tau3     float64\n",
       "tau4     float64\n",
       "p1       float64\n",
       "p2       float64\n",
       "p3       float64\n",
       "p4       float64\n",
       "g1       float64\n",
       "g2       float64\n",
       "g3       float64\n",
       "g4       float64\n",
       "stab     float64\n",
       "stabf     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "906e7b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     0\n",
       "tau2     0\n",
       "tau3     0\n",
       "tau4     0\n",
       "p1       0\n",
       "p2       0\n",
       "p3       0\n",
       "p4       0\n",
       "g1       0\n",
       "g2       0\n",
       "g3       0\n",
       "g4       0\n",
       "stab     0\n",
       "stabf    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b2af8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr=df.corr()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr,cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21adfca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tau1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau3</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau4</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1</th>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p3</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p4</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g3</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stab</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tau1  tau2  tau3  tau4    p1    p2    p3    p4    g1    g2    g3    g4  \\\n",
       "tau1  1.00  0.02 -0.01 -0.02  0.03 -0.02 -0.02 -0.02  0.01  0.02 -0.00  0.01   \n",
       "tau2  0.02  1.00  0.01 -0.00 -0.00  0.01  0.01 -0.01 -0.00  0.02  0.02 -0.01   \n",
       "tau3 -0.01  0.01  1.00  0.00  0.02 -0.00 -0.01 -0.02 -0.01  0.01  0.01 -0.01   \n",
       "tau4 -0.02 -0.00  0.00  1.00 -0.00  0.01  0.01 -0.01 -0.00  0.01  0.00 -0.00   \n",
       "p1    0.03 -0.00  0.02 -0.00  1.00 -0.57 -0.58 -0.58  0.00  0.02  0.00 -0.02   \n",
       "p2   -0.02  0.01 -0.00  0.01 -0.57  1.00  0.00 -0.01  0.02 -0.02  0.01  0.02   \n",
       "p3   -0.02  0.01 -0.01  0.01 -0.58  0.00  1.00  0.01 -0.00 -0.01 -0.01 -0.01   \n",
       "p4   -0.02 -0.01 -0.02 -0.01 -0.58 -0.01  0.01  1.00 -0.01  0.00 -0.00  0.02   \n",
       "g1    0.01 -0.00 -0.01 -0.00  0.00  0.02 -0.00 -0.01  1.00  0.01 -0.01  0.01   \n",
       "g2    0.02  0.02  0.01  0.01  0.02 -0.02 -0.01  0.00  0.01  1.00 -0.01 -0.01   \n",
       "g3   -0.00  0.02  0.01  0.00  0.00  0.01 -0.01 -0.00 -0.01 -0.01  1.00  0.01   \n",
       "g4    0.01 -0.01 -0.01 -0.00 -0.02  0.02 -0.01  0.02  0.01 -0.01  0.01  1.00   \n",
       "stab  0.28  0.29  0.28  0.28  0.01  0.01 -0.00 -0.02  0.28  0.29  0.31  0.28   \n",
       "\n",
       "      stab  \n",
       "tau1  0.28  \n",
       "tau2  0.29  \n",
       "tau3  0.28  \n",
       "tau4  0.28  \n",
       "p1    0.01  \n",
       "p2    0.01  \n",
       "p3   -0.00  \n",
       "p4   -0.02  \n",
       "g1    0.28  \n",
       "g2    0.29  \n",
       "g3    0.31  \n",
       "g4    0.28  \n",
       "stab  1.00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(df.corr(),2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39b61d36",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cd8197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "X = df.drop(['stabf', 'stab'], axis=1)\n",
    "Y=df['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f98a3055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.818"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "model=LogisticRegression(random_state=0,multi_class='ovr',solver='lbfgs')\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc939149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9515"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm \n",
    "svm_model = svm.SVC(kernel='rbf',C=30,gamma='auto')\n",
    "svm_model.fit(X_train,y_train)\n",
    "svm_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34febbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted target value: ['1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ML\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the RandomForestClassifier class with desired hyperparameters\n",
    "rfc = RandomForestClassifier(n_estimators=50, min_samples_split=5, min_samples_leaf=2, max_features='sqrt', max_depth=None)\n",
    "\n",
    "# Fit the classifier on the training data\n",
    "rfc.fit(X_train, y_train)\n",
    "new_data = [[0.82,5.42,9.43,2.48,3.04, -1.46, -0.935, -0.638,0.702, 0.1160, 0.57,0.578]]\n",
    "\n",
    "# Make a prediction using the new data\n",
    "prediction = rfc.predict(new_data)\n",
    "\n",
    "# Print the predicted target value\n",
    "print(\"Predicted target value:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bf13856",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power 1:  4.0 mW\n",
      "Power 2:  0.0 mW\n",
      "Power 3:  0.0 mW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ML\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted target value: ['1']\n",
      "Power 1:  4.0 mW\n",
      "Power 2:  0.0 mW\n",
      "Power 3:  0.0 mW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ML\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted target value: ['1']\n",
      "Power 1:  4.0 mW\n",
      "Power 2:  0.0 mW\n",
      "Power 3:  0.0 mW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ML\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted target value: ['1']\n",
      "Power 1:  4.0 mW\n",
      "Power 2:  0.0 mW\n",
      "Power 3:  0.0 mW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ML\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted target value: ['1']\n",
      "Power 1:  4.0 mW\n",
      "Power 2:  0.0 mW\n",
      "Power 3:  0.0 mW\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPower 2: \u001b[39m\u001b[38;5;124m\"\u001b[39m, power2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmW\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPower 3: \u001b[39m\u001b[38;5;124m\"\u001b[39m, power3, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmW\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mrfc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m new_data \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m0.82\u001b[39m,\u001b[38;5;241m5.42\u001b[39m,\u001b[38;5;241m9.43\u001b[39m,\u001b[38;5;241m2.48\u001b[39m,\u001b[38;5;241m3.04\u001b[39m, \u001b[38;5;241m-\u001b[39mpower1\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m-\u001b[39mpower2\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m-\u001b[39mpower3\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m40\u001b[39m,\u001b[38;5;241m0.702\u001b[39m, \u001b[38;5;241m0.1160\u001b[39m, \u001b[38;5;241m0.57\u001b[39m,\u001b[38;5;241m0.578\u001b[39m]]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Make a prediction using the new data\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ML\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    439\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    442\u001b[0m ]\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mD:\\ML\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ML\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ML\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mD:\\ML\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mD:\\ML\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ML\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\ML\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\ML\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\ML\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\ML\\lib\\site-packages\\sklearn\\tree\\_classes.py:214\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    212\u001b[0m y_encoded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(y\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_):\n\u001b[1;32m--> 214\u001b[0m     classes_k, y_encoded[:, k] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y[:, k], return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mappend(classes_k)\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\u001b[38;5;241m.\u001b[39mappend(classes_k\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import serial\n",
    "\n",
    "ser = serial.Serial('COM4', 115200, timeout=1)\n",
    "ser.flush()\n",
    "\n",
    "while True:\n",
    "    if ser.in_waiting > 0:\n",
    "        data = ser.readline().decode().strip()\n",
    "        powers = data.split(',')\n",
    "        if len(powers) >= 3 and powers[0] != '' and powers[1] != '' and powers[2] != '':\n",
    "            power1 = float(powers[0])\n",
    "            power2 = float(powers[1])\n",
    "            power3 = float(powers[2])\n",
    "            print(\"Power 1: \", power1, \"mW\")\n",
    "            print(\"Power 2: \", power2, \"mW\")\n",
    "            print(\"Power 3: \", power3, \"mW\")\n",
    "            rfc.fit(X_train, y_train)\n",
    "            new_data = [[0.82,5.42,9.43,2.48,3.04, -power1/200, -power2/200, -power3/40,0.702, 0.1160, 0.57,0.578]]\n",
    "\n",
    "            # Make a prediction using the new data\n",
    "            prediction = rfc.predict(new_data)\n",
    "\n",
    "            # Print the predicted target value\n",
    "            print(\"Predicted target value:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639afaf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
